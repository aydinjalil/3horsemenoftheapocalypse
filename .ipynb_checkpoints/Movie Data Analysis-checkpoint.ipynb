{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study: Movie Data Analysis\n",
    "\n",
    "This notebook uses a dataset from the MovieLens website.\n",
    "\n",
    "* Data SourceL MovieLens web site (filename: ml-20m.zip)\n",
    "* Location https://grouplens.org/datasets/movielens\n",
    "\n",
    "\n",
    "First Let's explore the folder to see what files we have in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -la ./movielens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Pandas to read data\n",
    "\n",
    "In this notebook, we will be using three CSV files:\n",
    "\n",
    "* ratings.csv: userId, movieId, rating, timestamp\n",
    "* tags.csv: userId, movieId, tag, timestamp\n",
    "* movies.csv: movieId, title, genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data = pd.read_csv('./movielens/movies.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Timestamps represent seconds since midnight Coordinated Universal Time (UTC)\n",
    "tags = pd.read_csv('./movielens/tags.csv', sep=\",\")\n",
    "tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('./movielens/ratings.csv', sep=\",\")\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We do not need timestamp column right now but we will get back to it later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ratings['timestamp']\n",
    "del tags['timestamp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings['rating'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings['rating'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings['rating'].min(), ratings['rating'].max(), ratings['rating'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings['rating'].mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick sanity check\n",
    "\n",
    "Here we are verifying adequacy of ratings by checking if there are any ratings greater than 5 or less than 0. It is unneccessary since we know min and max ratings values but this is an alternative way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_1 = ratings['rating'] > 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_1.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_2 = ratings['rating'] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_2.all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning: Handling missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_ = tags['tag'].isnull()\n",
    "null_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_tags = tags[null_]\n",
    "null_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_tag_movies = null_tags['movieId']\n",
    "pd.DataFrame(movie_data, index=null_tag_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since we have null values for tags, let's drop them to have a cleaner dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = tags.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract year from title e.g (1995)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data['year'] = movie_data['title'].str.extract(\".*\\((.*)\\).*\", expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Data - average movie ratings over time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_rating = ratings[['movieId', 'rating']].groupby('movieId', as_index=False).mean()\n",
    "average_rating.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = movie_data.merge(average_rating, on='movieId', how='inner')\n",
    "joined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify Data to be used in Twitter API request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_mask = joined.rating  > 4\n",
    "year_mask = joined.year > '2010'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = joined[rating_mask & year_mask]\n",
    "final_data = final_data.reset_index().drop(columns='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "titles = np.array(final_data.title)\n",
    "for index, title in np.ndenumerate(titles):\n",
    "    final_data.loc[index, 'title'] = title.split(\"(\")[0]\n",
    "final_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "final_data = final_data.drop(final_data[final_data.title.str.contains(\", The\")].index, inplace = False)\n",
    "final_data = final_data.reset_index().drop(columns='index')\n",
    "titles = np.array(final_data.title)\n",
    "for index, title in np.ndenumerate(titles):\n",
    "    final_data.loc[index, 'hashtags'] = \"#\" +  title.replace(\" \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter API access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "\n",
    "import os\n",
    "import tweepy as tw\n",
    "import json\n",
    "from pprint import pprint\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tw.OAuthHandler(config.consumer_key, config.consumer_secret)\n",
    "auth.set_access_token(config.access_token, config.access_token_secret)\n",
    "api = tw.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not os.path.exists('secret_twitter_credentials.pkl'):\n",
    "#     Twitter={}\n",
    "#     Twitter['Consumer Key'] = config.consumer_key\n",
    "#     Twitter['Consumer Secret'] = config.consumer_secret\n",
    "#     Twitter['Access Token'] = config.access_token\n",
    "#     Twitter['Access Token Secret'] = config.access_token_secret\n",
    "#     with open('secret_twitter_credentials.pkl','wb') as f:\n",
    "#         pickle.dump(Twitter, f)\n",
    "# else:\n",
    "#     Twitter=pickle.load(open('secret_twitter_credentials.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import twitter\n",
    "\n",
    "# auth = twitter.oauth.OAuth(Twitter['Access Token'],\n",
    "#                            Twitter['Access Token Secret'],\n",
    "#                            Twitter['Consumer Key'],\n",
    "#                            Twitter['Consumer Secret'])\n",
    "\n",
    "# twitter_api = twitter.Twitter(auth=auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where on Earth ID number.. this helps to find location based on ID\n",
    "\n",
    "This was not needed since we found different way to pull data from twitter but still nice to have for future references\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORLD_WOE_ID = 1\n",
    "# US_WOE_ID = 23424977\n",
    "# LOCAL_WOE_ID=2357024 # Atlanta WOEID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# world_trends = twitter_api.trends.place(_id=WORLD_WOE_ID)\n",
    "# us_trends = twitter_api.trends.place(_id=US_WOE_ID)\n",
    "# local_trends = twitter_api.trends.place(_id=LOCAL_WOE_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twitter_pull(hash):\n",
    "    users_and_text = {}\n",
    "    tweet_list = ''\n",
    "    tweets = tw.Cursor(api.search,\n",
    "        q=hash,\n",
    "            lang=\"en\").items(1)\n",
    "    for tweet in tweets:\n",
    "        users_and_text[\"hashtag\"] = hash\n",
    "        users_and_text[\"user_name\"] = tweet.user.screen_name\n",
    "        users_and_text[\"tweet\"] = tweet.text\n",
    "        users_and_text[\"location\"] = tweet.user.location\n",
    "#     users_and_text = [[tweet.user.screen_name, tweet.text, tweet.user.location] for tweet in tweets]\n",
    "    return users_and_text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twits = []\n",
    "for hash in final_data.hashtags:\n",
    "    twits.append(twitter_pull(hash))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in twits:\n",
    "    print(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, _dict in enumerate(twits):\n",
    "    if bool(_dict):\n",
    "        final_data.loc[index, 'user_name'] = _dict['user_name']\n",
    "        final_data.loc[index, 'tweet'] = _dict['tweet']\n",
    "        final_data.loc[index, 'location'] = _dict['location']\n",
    "    else:\n",
    "        final_data.loc[index, 'user_name'] = \"Nan\"\n",
    "        final_data.loc[index, 'tweet'] = \"Nan\"\n",
    "        final_data.loc[index, 'location'] = \"Nan\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = final_data.drop(final_data[final_data.tweet.str.contains(\"Nan\")].index, inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python37]",
   "language": "python",
   "name": "conda-env-python37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
